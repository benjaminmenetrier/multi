\documentclass[francais]{beamer}
\usepackage[francais]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{amsmath, amssymb, amsfonts}




%CHOIX DU THEME et/ou DE SA COULEUR
% => essayer différents thèmes (en décommantant une des trois lignes suivantes)
%\usetheme{PaloAlto}
\usetheme{Madrid}

% => il est possible, pour un thème donné, de modifier seulement la couleur
\usecolortheme{default}
%\usecolortheme{whale}

%\useoutertheme[left]{sidebar}


%Pour le TITLEPAGE


\title[Nicolas Baillot d'Etivaux]{Constraining the equation of state for dense matter through thermal emission of neutron stars}


%Debut de la presentation :

\begin{document}


%Présentation:
\setbeamertemplate{blocks}[rounded]%
[shadow=false]


\begin{frame}{Content}
\begin{itemize}
\item Full resolution example:
\begin{itemize}
\item Background state and observations
\item B matrix monitoring
\item Innovation vs. guess
\item Cost function
\end{itemize}
\item Changing the resolution:
\begin{itemize}
\item illustration of the change on the background state.
\item Modifications on the guess.
\item Cost function.
\end{itemize}
\item Short conclusion
\end{itemize}
\end{frame}

\begin{frame}{Parameters of the example}
The aim of this presentation is to monitor the output of the code multi 2D and spot the potential problems and reassuring things.\\
The parameters of the code are fixed to the following:\\

\begin{itemize}
\item outer ierations: 4, inner iterations: 6, no stop criterion.
\item no LMP are used.
\item $\sigma^b_{var}$=0.1, $L_b=0.1$ (correlation lenghtscale), minimum spectral variance: $10^{-5}$.
\item $n_{obs}=2000$, $\sigma^o=0.01$.
\item others: transitive interpolation: True / Projective Bmatrix: True / no orthogonality test.
\item method used to compute the increments at outer loop level: "theoretical" (using $B^{-1}$) -- see the notes of Benjamin.
\end{itemize}
\end{frame}

\begin{frame}{Full resolution}
\begin{center}
{\huge Full resolution example.}\\
\vspace{+1cm}
The resolution is fixed at $nx\times ny=101 \times 101$ for the example. The problem is modeled in a square domain of size 1, divided in $n_x \times n_y$ pixels.\\
\end{center}
\end{frame}

\begin{frame}{Full resolution: Background state and Observations}
\begin{center}
The background and observations generated randomly seems to be good.\\
\begin{figure}
\minipage{0.49\textwidth}
  \includegraphics[width=\linewidth]{images/xb.png}
  \caption{background state $x^b$.}
\endminipage\hfill
\minipage{0.49\textwidth}
  \includegraphics[width=\linewidth]{images/obs.png}
  \caption{Observations.}
\endminipage
\end{figure}
\end{center}
\end{frame}

\begin{frame}{Full resolution: B matrix}
\begin{center}
The B matrix is OK: The correlation lenghtscale modifies the figures as expected (not shown), and one can see that the left panel shows correlations consistent with the periodic domain in which we are working.\\ 
\begin{figure}
\minipage{0.49\textwidth}
  \includegraphics[width=0.8\linewidth]{images/sigmab.png}
  \caption{Background error field $\sigma^b$.}
\endminipage\hfill
\minipage{0.49\textwidth}
  \includegraphics[width=0.8\linewidth]{images/dirac_cor.png}
  \caption{B applied to a "dirac": ($B(1,0,0,..,0)^T$)}
\endminipage
\end{figure}
\end{center}
\end{frame}

% guess -------------------------------------------------------------
\begin{frame}{Full resolution: guess}
\begin{center}
With lanczos algorithm:\\
The problem have been fixed: The first guess is now the background state.
\begin{figure}
\minipage{0.49\textwidth}
  \includegraphics[width=0.8\linewidth]{images/lxg1.png}
  \caption{guess (outer iteration 1)}
\endminipage\hfill
\minipage{0.49\textwidth}
  \includegraphics[width=0.8\linewidth]{images/lxg2.png}
  \caption{guess (outer iteration 2)}
\endminipage
\end{figure}
\end{center}
\end{frame}

\begin{frame}{Full resolution: guess}
\begin{center}
With lanczos algorithm:
\begin{figure}
\minipage{0.49\textwidth}
  \includegraphics[width=0.8\linewidth]{images/lxg3.png}
  \caption{guess (outer iteration 3)}
\endminipage \hfill
\minipage{0.49\textwidth}%
  \includegraphics[width=0.8\linewidth]{images/lxg4.png}
  \caption{guess (outer iteration 4)}
\endminipage
\end{figure}
\end{center}
\end{frame}

\begin{frame}{Full resolution: guess}
\begin{center}
With PlanczosIF algorithm (same results as using lanczos):\\
\begin{figure}
\minipage{0.49\textwidth}
  \includegraphics[width=0.8\linewidth]{images/pxg1.png}
  \caption{guess (outer iteration 1)}
\endminipage\hfill
\minipage{0.49\textwidth}
  \includegraphics[width=0.8\linewidth]{images/pxg2.png}
  \caption{guess (outer iteration 2)}
\endminipage
\end{figure}
\end{center}
\end{frame}

\begin{frame}{Full resolution: guess}
\begin{center}
With PlanczosIF algorithm (same results as using lanczos):
\begin{figure}
\minipage{0.49\textwidth}
  \includegraphics[width=0.8\linewidth]{images/pxg3.png}
  \caption{guess (outer iteration 3)}
\endminipage \hfill
\minipage{0.49\textwidth}%
  \includegraphics[width=0.8\linewidth]{images/pxg4.png}
  \caption{guess (outer iteration 4)}
\endminipage
\end{figure}
\end{center}
\end{frame}
%------------------------------

% hxg -------------------------------------------------------------
\begin{frame}{Full resolution: mapping the guess to the obs: $H x^g$}
\begin{center}
lanczos example (identical with PlanczosIF):
\begin{figure}
\minipage{0.49\textwidth}
  \includegraphics[width=\linewidth]{images/lhxg1.png}
  \caption{$H x^g$ (outer iteration 1)}
\endminipage\hfill
\minipage{0.49\textwidth}
  \includegraphics[width=\linewidth]{images/lhxg2.png}
  \caption{$H x^g$ (outer iteration 2)}
\endminipage
\end{figure}
\end{center}
\end{frame}

\begin{frame}{Full resolution: mapping the guess to the obs: $H x^g$}
\begin{center}
$Hx^g$ seems to be close to the background state at the beggining and closer to the obs at the end (but with a higher variance than the observations ?). 
\begin{figure}
\minipage{0.49\textwidth}
  \includegraphics[width=\linewidth]{images/lhxg3.png}
  \caption{$H x^g$ (outer iteration 3)}
\endminipage \hfill
\minipage{0.49\textwidth}%
  \includegraphics[width=\linewidth]{images/lhxg4.png}
  \caption{$H x^g$ (outer iteration 4)}
\endminipage
\end{figure}
\end{center}
\end{frame}
%-------------------------------------------------------------

% innovation -------------------------------------------------------------
\begin{frame}{Full resolution: innovations}
\begin{center}
lanczos example (identical with PlanczosIF):
\begin{figure}
\minipage{0.49\textwidth}
  \includegraphics[width=\linewidth]{images/d1.png}
  \caption{innovation (outer iteration 1)}
\endminipage\hfill
\minipage{0.49\textwidth}
  \includegraphics[width=\linewidth]{images/d2.png}
  \caption{innovation (outer iteration 2)}
\endminipage
\end{figure}
\end{center}
\end{frame}

\begin{frame}{Full resolution: innovations}
\begin{center}
Are the values of the innovation small enough ?
\begin{figure}
\minipage{0.49\textwidth}
  \includegraphics[width=\linewidth]{images/d3.png}
  \caption{innovation (outer iteration 3)}
\endminipage \hfill
\minipage{0.49\textwidth}%
  \includegraphics[width=\linewidth]{images/d4.png}
  \caption{innovation (outer iteration 4)}
\endminipage
\end{figure}
\end{center}
\end{frame}
%-------------------------------------------------------------


\begin{frame}{Full resolution: Cost function}
\begin{center}
In the following slides, we compare the cost functions obtained with the different methods ("theoretical", "standard", and "alternative") with both lanczos algorithms in control space and PlanczosIF in model space.\\
\vspace{+1cm}
The code allows to retrieve the non linear cost functions (departure from the background $J^{nl}_b$, from the observations $J^{nl}_o$ and there sum $J^{nl}$) as well as the linearized ones $J_b,J_o$, and $J$.
\vspace{+1cm}
The blue dashed lines represent the outer iterations. The lower panel illustrates the difference between the result in control space or model space for each method.\\
\end{center}
\end{frame}

% cost function:----------------------------------------------------------------------------
\begin{frame}{Full resolution: Cost function}
\begin{center}
\minipage{0.39\textwidth}
non linear total cost function $J^{nl}=J^{nl}_o + J^{nl}_b$.\\
1) The code converges with all the methods.\\
2) The differences between the methods seems small (as well as the difference between the two algorithms for each methods -- lower panel).\\
\endminipage \hfill
\minipage{0.59\textwidth}%
\begin{figure}
  \includegraphics[width=\linewidth]{images/jnl.png}
\end{figure}
\endminipage
\end{center}
\end{frame}


\begin{frame}{Full resolution: Cost function}
\begin{center}
The observational part of the cost function seems to be good...
 \includegraphics[scale=0.3]{./images/jonl.png}
\end{center}
\end{frame}

\begin{frame}{Full resolution: Cost function}
\begin{center}
... as well as the background contribution.
 \includegraphics[scale=0.3]{./images/jbnl.png}
\end{center}
\end{frame}

\begin{frame}{Full resolution: Cost function}
\begin{center}
\minipage{0.39\textwidth}
There is a small difference between the linearized cost function and the non-linear one, as expected, but stronger for the "theoretical" method (?).
\endminipage \hfill
\minipage{0.59\textwidth}%
\begin{figure}
  \includegraphics[width=\linewidth]{images/jb.png}
\end{figure}
\endminipage
\end{center}
\end{frame}

\begin{frame}{Full resolution: Cost function}
\begin{center}
\minipage{0.39\textwidth}
$\beta$ is the ratio between the norm of the residue at inner iterations i and i+1 (see Benjamin's notes).\\
I think there is a problem in the inner iterations or with the storing of $\beta$ because we can see the peak is delayed of one inner iteration at each outer iterations. (I will check that issue, it might also be in my plotting code).
\endminipage \hfill
\minipage{0.59\textwidth}%
\begin{figure}
  \includegraphics[width=\linewidth]{images/beta.png}
\end{figure}
\endminipage
\end{center}
\end{frame}

\begin{frame}{Full resolution: Cost function}
\begin{center}
\minipage{0.39\textwidth}
$\rho$ is the norm of the residue and seems to converge well.
\endminipage \hfill
\minipage{0.59\textwidth}%
\begin{figure}
  \includegraphics[width=\linewidth]{images/rho.png}
\end{figure}
\endminipage
\end{center}
\end{frame}


\begin{frame}{Differences between the methods}
\begin{center}
\minipage{0.39\textwidth}
There are small differences between the guesses obtained with the "alternative" and "theoretical" methods as illustrated with this example, whereas there are not between "standard" and "theoretical" methods.\\
The differences appear after the firsts outer loops.
\endminipage \hfill
\minipage{0.59\textwidth}%
\begin{figure}
  \includegraphics[width=0.8\linewidth]{images/ldiffaltvsth3.png}
  \caption{$x^g_{alt}-x^g_{th}$ (lanczos example)}
\end{figure}
\endminipage
\end{center}
\end{frame}
% Changing the resolution ------------------------------------------------------------------------------------------


\begin{frame}
\begin{center}
  {\huge Canging the resolution}\\
  \vspace{+1cm}
In the following, we choose the resolutions for the outer iterations to be:\\
outer 1: $n_x \times n_y = 101 \times 101$,\\
outer 2: $n_x \times n_y = 121 \times 121$,\\
outer 3: $n_x \times n_y = 151 \times 151$,\\
outer 4: $n_x \times n_y = 201 \times 201$.
\end{center}
\end{frame}

% xb -------------------------------------------------------------
\begin{frame}{Changing resolution: $x^b$}
\begin{center}
The change of resolution is OK for the background (idem for the B matrix -- not shown).
\begin{figure}
\minipage{0.49\textwidth}
  \includegraphics[width=0.8\linewidth]{images/xb1r.png}
  \caption{$x^b$ (outer iteration 1)}
\endminipage\hfill
\minipage{0.49\textwidth}
  \includegraphics[width=0.8\linewidth]{images/xb2r.png}
  \caption{$x^b$ (outer iteration 2)}
\endminipage
\end{figure}
\end{center}
\end{frame}

\begin{frame}{Changing resolution: $x^b$}
\begin{center}
\begin{figure}
\minipage{0.49\textwidth}
  \includegraphics[width=0.8\linewidth]{images/xb3r.png}
  \caption{$x^b$ (outer iteration 3)}
\endminipage \hfill
\minipage{0.49\textwidth}%
  \includegraphics[width=0.8\linewidth]{images/xb4r.png}
  \caption{$x^b$ (outer iteration 4)}
\endminipage
\end{figure}
\end{center}
\end{frame}
%-------------------------------------------------------------


% guess -------------------------------------------------------------
\begin{frame}{Changing resolution: guess}
\begin{center}
With lanczos algorithm (identical with PlanczosIF): The problem is fixed
\begin{figure}
\minipage{0.49\textwidth}
  \includegraphics[width=0.8\linewidth]{images/lxg1r.png}
  \caption{guess (outer iteration 1)}
\endminipage\hfill
\minipage{0.49\textwidth}
  \includegraphics[width=0.8\linewidth]{images/lxg2r.png}
  \caption{guess (outer iteration 2)}
\endminipage
\end{figure}
\end{center}
\end{frame}

\begin{frame}{Changing resolution: guess}
\begin{center}
With lanczos algorithm:
\begin{figure}
\minipage{0.49\textwidth}
  \includegraphics[width=0.8\linewidth]{images/lxg3r.png}
  \caption{guess (outer iteration 3)}
\endminipage \hfill
\minipage{0.49\textwidth}%
  \includegraphics[width=0.8\linewidth]{images/lxg4r.png}
  \caption{guess (outer iteration 4)}
\endminipage
\end{figure}
\end{center}
\end{frame}


\begin{frame}{Changing resolution: cost function}
\begin{center}
\minipage{0.39\textwidth}
The convergence is correct, also for $J_o$ and $J_b$ (in the current state of the code, we do not add new observations at outer iterations level, so there is no artificial deterioring of the cost function at each outer iterations).\\
\endminipage \hfill
\minipage{0.59\textwidth}%
\begin{figure}
  \includegraphics[width=\linewidth]{images/jnlr.png}
\end{figure}
\endminipage
\end{center}
\end{frame}
%------------------------------------------------------------------------------------------


% Conclusions ------------------------------------------------------------------------------------------
\begin{frame}{Short conclusion:}
\begin{itemize}
 \item The code seems to converge to a correct solution according to the innovation, cost function and residual norm, both in full resolution or changing it.
 \item There is no significant difference between the three methods or between the algorithms used in both scenarios for the resolution.
 \item There is a small difference between non-linear and linearized cost functions.
 \item There are small differences in the guess appearing after the first outer loops between the alternative and theoretical methods, but not between the standard and theoretical methods.
 \item Need to check beta (outer loops problem?)
\end{itemize}
\end{frame}
%------------------------------------------------------------------------------------------






\usebackgroundtemplate{}




\end{document}
